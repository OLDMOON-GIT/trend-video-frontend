/**
 * ìë™í™” ìŠ¤ì¼€ì¤„ëŸ¬ ë° íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
 * ì œëª© â†’ ëŒ€ë³¸ ìƒì„± â†’ ì˜ìƒ ìƒì„± â†’ ìœ íŠœë¸Œ ì—…ë¡œë“œ â†’ í¼ë¸”ë¦¬ì‹œ
 */

import {
  getPendingSchedules,
  getWaitingForUploadSchedules,
  createPipeline,
  updatePipelineStatus,
  updateScheduleStatus,
  addPipelineLog,
  addTitleLog,
  getAutomationSettings
} from './automation';
import { sendErrorEmail } from './email';
import Database from 'better-sqlite3';
import path from 'path';
import fs from 'fs';

const dbPath = path.join(process.cwd(), 'data', 'database.sqlite');

// ìŠ¤ì¼€ì¤„ëŸ¬ ì¸í„°ë²Œ
let schedulerInterval: NodeJS.Timeout | null = null;
let isRunning = false;

// ì œëª© ìƒíƒœ ì—…ë°ì´íŠ¸ í—¬í¼ í•¨ìˆ˜
function updateTitleStatus(titleId: string, status: 'pending' | 'scheduled' | 'processing' | 'completed' | 'failed' | 'waiting_for_upload' | 'cancelled') {
  try {
    const db = new Database(dbPath);
    db.prepare(`
      UPDATE video_titles
      SET status = ?, updated_at = CURRENT_TIMESTAMP
      WHERE id = ?
    `).run(status, titleId);
    db.close();
    console.log(`ğŸ“ [Title Status] ${titleId} â†’ ${status}`);
  } catch (error) {
    console.error('Failed to update title status:', error);
  }
}

// ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
export function startAutomationScheduler() {
  if (schedulerInterval) {
    console.log('âš ï¸ Scheduler is already running');
    return;
  }

  const settings = getAutomationSettings();
  const enabled = settings.enabled === 'true';
  // ìµœì†Œ 3ì´ˆ ê°„ê²© (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
  const checkInterval = Math.max(3, parseInt(settings.check_interval || '10')) * 1000;

  if (!enabled) {
    console.log('âš ï¸ Automation is disabled in settings');
    return;
  }

  console.log(`âœ… Automation scheduler started (checking every ${checkInterval / 1000}s)`);

  // ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰
  processPendingSchedules();
  checkAndCreateAutoSchedules(); // ì™„ì „ ìë™í™”: ì±„ë„ ì£¼ê¸° ì²´í¬ ë° ìë™ ìŠ¤ì¼€ì¤„ ìƒì„±

  // ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
  schedulerInterval = setInterval(() => {
    processPendingSchedules();
    checkWaitingForUploadSchedules(); // ì´ë¯¸ì§€ ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ ì²´í¬
    checkReadyToUploadSchedules(); // ì˜ìƒ ìƒì„± ì™„ë£Œë˜ì–´ ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ ì²´í¬
    checkAndCreateAutoSchedules(); // ì™„ì „ ìë™í™”: ì±„ë„ ì£¼ê¸° ì²´í¬ ë° ìë™ ìŠ¤ì¼€ì¤„ ìƒì„±
  }, checkInterval);
}

// ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€
export function stopAutomationScheduler() {
  if (schedulerInterval) {
    clearInterval(schedulerInterval);
    schedulerInterval = null;
    console.log('â¸ï¸ Automation scheduler stopped (ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì€ ê³„ì† ì‹¤í–‰ë¨)');
    console.log('ğŸ’¡ Note: ì´ë¯¸ ì‹œì‘ëœ íŒŒì´í”„ë¼ì¸ì€ í¬ë ˆë”§ì´ ì°¨ê°ë˜ì—ˆìœ¼ë¯€ë¡œ ì™„ë£Œê¹Œì§€ ì§„í–‰ë©ë‹ˆë‹¤.');
  }
}

// ì˜ˆì•½ëœ ìŠ¤ì¼€ì¤„ ì²˜ë¦¬
async function processPendingSchedules() {
  if (isRunning) {
    console.log('âš ï¸ Previous schedule processing is still running, skipping...');
    return;
  }

  isRunning = true;

  try {
    const pendingSchedules = getPendingSchedules();

    if (pendingSchedules.length === 0) {
      console.log('[Scheduler] No pending schedules');
      return;
    }

    console.log(`[Scheduler] Found ${pendingSchedules.length} pending schedule(s)`);

    // Debug: ì²«ë²ˆì§¸ ìŠ¤ì¼€ì¤„ì˜ ì „ì²´ í‚¤ ë¡œê¹…
    if (pendingSchedules.length > 0) {
      console.log('ğŸ” [SCHEDULER] First schedule keys:', Object.keys(pendingSchedules[0]));
      console.log('ğŸ” [SCHEDULER] First schedule has product_data?:', !!(pendingSchedules[0] as any).product_data);
    }

    for (const schedule of pendingSchedules) {
      try {
        // íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸ (DB ì ê¸ˆìœ¼ë¡œ race condition ë°©ì§€)
        const db = new Database(dbPath);

        const existingPipeline = db.prepare(`
          SELECT id FROM automation_pipelines WHERE schedule_id = ? LIMIT 1
        `).get((schedule as any).id);

        if (existingPipeline) {
          console.log(`[Scheduler] Pipeline already exists for schedule ${(schedule as any).id}, skipping`);
          db.close();
          continue;
        }

        // ì›ìì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ ìƒíƒœë¥¼ 'processing'ìœ¼ë¡œ ë³€ê²½ (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
        const result = db.prepare(`
          UPDATE video_schedules
          SET status = 'processing', updated_at = CURRENT_TIMESTAMP
          WHERE id = ? AND status = 'pending'
        `).run((schedule as any).id);

        // ì—…ë°ì´íŠ¸ëœ rowê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì²˜ë¦¬ ì¤‘
        if (result.changes === 0) {
          console.log(`[Scheduler] Schedule ${(schedule as any).id} already being processed by another scheduler`);
          db.close();
          continue;
        }

        // ì¦‰ì‹œ íŒŒì´í”„ë¼ì¸ ìƒì„± (ê°™ì€ DB ì—°ê²° ì‚¬ìš©í•˜ì—¬ ì›ìì„± ë³´ì¥)
        const stages = ['script', 'video', 'upload', 'publish'];
        const pipelineIds: string[] = [];

        try {
          for (const stage of stages) {
            const id = `pipeline_${Date.now()}_${stage}_${Math.random().toString(36).substr(2, 9)}`;
            try {
              db.prepare(`
                INSERT INTO automation_pipelines (id, schedule_id, stage, status)
                VALUES (?, ?, ?, 'pending')
              `).run(id, (schedule as any).id, stage);
              pipelineIds.push(id);
            } catch (insertError: any) {
              // UNIQUE ì œì•½ì¡°ê±´ ìœ„ë°˜ (ì´ë¯¸ ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ìƒì„±í•¨)
              if (insertError.code === 'SQLITE_CONSTRAINT_UNIQUE' || insertError.message?.includes('UNIQUE')) {
                console.log(`[Scheduler] Pipeline for stage ${stage} already exists for schedule ${(schedule as any).id}, using existing one`);
                // ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ID ê°€ì ¸ì˜¤ê¸°
                const existing = db.prepare(`
                  SELECT id FROM automation_pipelines WHERE schedule_id = ? AND stage = ?
                `).get((schedule as any).id, stage) as any;
                if (existing) {
                  pipelineIds.push(existing.id);
                }
              } else {
                throw insertError;
              }
            }
          }
        } catch (pipelineError) {
          db.close();
          throw pipelineError;
        }

        db.close();
        console.log(`[Scheduler] Created/Retrieved pipeline for schedule ${(schedule as any).id}`);

        // ì œëª© ìƒíƒœë„ 'processing'ìœ¼ë¡œ ë³€ê²½
        updateTitleStatus((schedule as any).title_id, 'processing');

        // íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰)
        executePipeline(schedule as any, pipelineIds).catch(error => {
          console.error(`[Scheduler] Pipeline execution failed for ${(schedule as any).id}:`, error);
        });

      } catch (error: any) {
        console.error(`[Scheduler] Failed to process schedule ${(schedule as any).id}:`, error);
        updateScheduleStatus((schedule as any).id, 'failed');
        updateTitleStatus((schedule as any).title_id, 'failed');

        // ì—ëŸ¬ ì´ë©”ì¼ ì „ì†¡
        await sendAutomationErrorEmail(
          (schedule as any).id,
          'schedule_processing',
          error.message,
          { schedule }
        );
      }
    }
  } catch (error) {
    console.error('[Scheduler] Error in processPendingSchedules:', error);
  } finally {
    isRunning = false;
  }
}

// íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
export async function executePipeline(schedule: any, pipelineIds: string[]) {
  const [scriptPipelineId, videoPipelineId, uploadPipelineId, publishPipelineId] = pipelineIds;
  const settings = getAutomationSettings();
  const maxRetry = parseInt(settings.max_retry || '3');

  try {
    // ============================================================
    // Stage 1: ëŒ€ë³¸ ìƒì„±
    // ============================================================
    addPipelineLog(scriptPipelineId, 'info', `Starting script generation for: ${schedule.title}`);
    addTitleLog(schedule.title_id, 'info', `Starting script generation for: ${schedule.title}`);
    updatePipelineStatus(scriptPipelineId, 'running');

    const scriptResult = await generateScript(schedule, scriptPipelineId, maxRetry);

    if (!scriptResult.success) {
      throw new Error(`Script generation failed: ${scriptResult.error}`);
    }

    updatePipelineStatus(scriptPipelineId, 'completed');

    // video_schedules í…Œì´ë¸”ì— script_id ì €ì¥
    const dbUpdate = new Database(dbPath);
    dbUpdate.prepare(`UPDATE video_schedules SET script_id = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?`)
      .run(scriptResult.scriptId, schedule.id);
    dbUpdate.close();

    updateScheduleStatus(schedule.id, 'processing', { scriptId: scriptResult.scriptId });
    addPipelineLog(scriptPipelineId, 'info', `Script generated successfully: ${scriptResult.scriptId}`);
    addTitleLog(schedule.title_id, 'info', `âœ… Script generated successfully: ${scriptResult.scriptId}`);

    // ============================================================
    // ìƒí’ˆ íƒ€ì…ì´ë©´ ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìë™ ìƒì„±
    // ============================================================
    if (schedule.type === 'product' || schedule.type === 'product-info') {
      addPipelineLog(scriptPipelineId, 'info', `ğŸ›ï¸ ìƒí’ˆ íƒ€ì… ê°ì§€ - ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì‹œì‘...`);
      addTitleLog(schedule.title_id, 'info', `ğŸ›ï¸ ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì¤‘...`);

      try {
        // ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ì½ê¸°
        addTitleLog(schedule.title_id, 'info', `ğŸ“– ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ì½ëŠ” ì¤‘...`);
        const dbReadScript = new Database(dbPath);
        const sourceScript = dbReadScript.prepare(`
          SELECT content FROM contents WHERE id = ?
        `).get(scriptResult.scriptId) as { content: string } | undefined;
        dbReadScript.close();

        if (!sourceScript || !sourceScript.content) {
          throw new Error('ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        }
        addTitleLog(schedule.title_id, 'info', `âœ… ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ ì™„ë£Œ`);

        // product-info í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì½ê¸°
        addTitleLog(schedule.title_id, 'info', `ğŸ“‹ ìƒí’ˆì„¤ëª… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì¤‘...`);
        const promptResponse = await fetch(`http://localhost:${process.env.PORT || 3000}/api/product-info-prompt`);
        if (!promptResponse.ok) {
          throw new Error('ìƒí’ˆì„¤ëª… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        }
        const promptData = await promptResponse.json();
        addTitleLog(schedule.title_id, 'info', `âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì™„ë£Œ`);

        // ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± API í˜¸ì¶œ
        const modelName = schedule.model === 'claude' ? 'Claude' : schedule.model === 'chatgpt' ? 'ChatGPT' : 'Gemini';
        addTitleLog(schedule.title_id, 'info', `ğŸ¤– ${modelName}ë¡œ ìƒí’ˆì„¤ëª… ìƒì„± ì¤‘... (1-2ë¶„ ì†Œìš”)`);

        const productInfoResponse = await fetch(`http://localhost:${process.env.PORT || 3000}/api/generate-script`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'X-Internal-Request': 'automation-system'
          },
          body: JSON.stringify({
            userId: schedule.user_id,
            prompt: promptData.prompt,
            topic: schedule.title,
            format: 'product-info',
            model: schedule.model || 'claude',
            productInfo: sourceScript.content // ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ì „ë‹¬
          })
        });

        if (!productInfoResponse.ok) {
          const errorText = await productInfoResponse.text();
          throw new Error(`ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± API ì‹¤íŒ¨: ${productInfoResponse.status} - ${errorText}`);
        }

        const productInfoData = await productInfoResponse.json();
        console.log(`âœ… [SCHEDULER] ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: ${productInfoData.id}`);
        addPipelineLog(scriptPipelineId, 'info', `âœ… ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: ${productInfoData.id}`);
        addTitleLog(schedule.title_id, 'info', `âœ… ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! (ID: ${productInfoData.id})`);
      } catch (error: any) {
        console.error(`âŒ [SCHEDULER] ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨:`, error);
        addPipelineLog(scriptPipelineId, 'warning', `âš ï¸ ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): ${error.message}`);
        addTitleLog(schedule.title_id, 'warning', `âš ï¸ ìƒí’ˆì„¤ëª… ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨ (ì˜ìƒ ìƒì„±ì€ ê³„ì†ë¨)`);
        // ìƒí’ˆì„¤ëª… ìƒì„± ì‹¤íŒ¨í•´ë„ ì˜ìƒ ìƒì„±ì€ ê³„ì† ì§„í–‰
      }
    }

    // ============================================================
    // ì§ì ‘ ì—…ë¡œë“œ ëª¨ë“œ ì²´í¬: media_modeê°€ 'upload'ì´ë©´ ì´ë¯¸ì§€ ì—…ë¡œë“œ ëŒ€ê¸°
    // ============================================================
    if (schedule.media_mode === 'upload') {
      // í”„ë¡œì íŠ¸ í´ë”ì™€ story.json ìƒì„±
      const BACKEND_PATH = path.join(process.cwd(), '..', 'trend-video-backend');
      const projectFolderPath = path.join(BACKEND_PATH, 'input', `project_${scriptResult.scriptId}`);

      try {
        // í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if (!fs.existsSync(projectFolderPath)) {
          fs.mkdirSync(projectFolderPath, { recursive: true });
          console.log(`ğŸ“ [SCHEDULER] í”„ë¡œì íŠ¸ í´ë” ìƒì„±: ${projectFolderPath}`);
        }

        // DBì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        const dbReadScript = new Database(dbPath);
        const scriptContent = dbReadScript.prepare(`
          SELECT content FROM contents WHERE id = ?
        `).get(scriptResult.scriptId) as { content: string } | undefined;
        dbReadScript.close();

        if (scriptContent && scriptContent.content) {
          // content íŒŒì‹±
          let contentStr = typeof scriptContent.content === 'string' ? scriptContent.content : JSON.stringify(scriptContent.content);

          // JSON ì •ë¦¬
          contentStr = contentStr.trim();
          if (contentStr.startsWith('JSON')) {
            contentStr = contentStr.substring(4).trim();
          }
          const jsonStart = contentStr.indexOf('{');
          if (jsonStart > 0) {
            contentStr = contentStr.substring(jsonStart);
          }

          // story.json ìƒì„±
          if (contentStr && contentStr.length > 0 && contentStr.includes('{')) {
            try {
              const scriptData = JSON.parse(contentStr);
              const storyJson = {
                ...scriptData,
                scenes: scriptData.scenes || []
              };

              const storyJsonPath = path.join(projectFolderPath, 'story.json');
              fs.writeFileSync(storyJsonPath, JSON.stringify(storyJson, null, 2), 'utf-8');
              console.log(`âœ… [SCHEDULER] story.json ìƒì„± ì™„ë£Œ: ${storyJsonPath}`);
              addTitleLog(schedule.title_id, 'info', `âœ… í”„ë¡œì íŠ¸ í´ë” ë° story.json ìƒì„± ì™„ë£Œ`);
            } catch (parseError: any) {
              console.error(`âŒ [SCHEDULER] JSON íŒŒì‹± ì‹¤íŒ¨: ${parseError.message}`);
              addTitleLog(schedule.title_id, 'warning', `âš ï¸ story.json ìƒì„± ì‹¤íŒ¨ (ìˆ˜ë™ìœ¼ë¡œ ëŒ€ë³¸ í™•ì¸ í•„ìš”)`);
            }
          } else {
            console.warn(`âš ï¸ [SCHEDULER] ëŒ€ë³¸ contentê°€ ë¹„ì–´ìˆê±°ë‚˜ JSONì´ ì•„ë‹˜`);
          }
        }
      } catch (folderError: any) {
        console.error(`âŒ [SCHEDULER] í´ë” ìƒì„± ì‹¤íŒ¨: ${folderError.message}`);
        addTitleLog(schedule.title_id, 'warning', `âš ï¸ í”„ë¡œì íŠ¸ í´ë” ìƒì„± ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)`);
      }

      updateScheduleStatus(schedule.id, 'waiting_for_upload', { scriptId: scriptResult.scriptId });
      updateTitleStatus(schedule.title_id, 'waiting_for_upload'); // íƒ€ì´í‹€ ìƒíƒœë„ ì—…ë°ì´íŠ¸
      addPipelineLog(videoPipelineId, 'info', `â¸ï¸ Waiting for manual image upload...`);
      addTitleLog(schedule.title_id, 'info', `â¸ï¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ì˜ìƒ ìƒì„±ì´ ì‹œì‘ë©ë‹ˆë‹¤.`);

      console.log(`[Scheduler] Schedule ${schedule.id} is waiting for manual image upload`);
      return; // ì´ë¯¸ì§€ ì—…ë¡œë“œ ëŒ€ê¸°, video ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì§€ ì•ŠìŒ
    }

    // ============================================================
    // Stage 2: ì˜ìƒ ìƒì„±
    // ============================================================
    addPipelineLog(videoPipelineId, 'info', `Starting video generation from script: ${scriptResult.scriptId}`);
    addTitleLog(schedule.title_id, 'info', `ğŸ¬ Starting video generation...`);
    updatePipelineStatus(videoPipelineId, 'running');

    const videoResult = await generateVideo(scriptResult.scriptId, videoPipelineId, maxRetry, schedule.title_id, schedule);

    if (!videoResult.success) {
      throw new Error(`Video generation failed: ${videoResult.error}`);
    }

    updatePipelineStatus(videoPipelineId, 'completed');

    // video_schedules í…Œì´ë¸”ì— video_id ì €ì¥
    const dbUpdateVideo = new Database(dbPath);
    dbUpdateVideo.prepare(`UPDATE video_schedules SET video_id = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?`)
      .run(videoResult.videoId, schedule.id);
    dbUpdateVideo.close();

    updateScheduleStatus(schedule.id, 'processing', { videoId: videoResult.videoId }); // completed ì•„ë‹ˆë¼ processing (ì—…ë¡œë“œ ì§„í–‰)
    addPipelineLog(videoPipelineId, 'info', `Video generated successfully: ${videoResult.videoId}`);
    addTitleLog(schedule.title_id, 'info', `âœ… Video generated successfully: ${videoResult.videoId}`);

    console.log(`[Scheduler] Video generation completed for schedule ${schedule.id}, continuing with upload...`);
    // return ì‚­ì œ - ìë™ìœ¼ë¡œ ì—…ë¡œë“œ ì§„í–‰

    // ============================================================
    // Stage 3: ìœ íŠœë¸Œ ì—…ë¡œë“œ
    // ============================================================
    addPipelineLog(uploadPipelineId, 'info', `Starting YouTube upload for video: ${videoResult.videoId}`);
    addTitleLog(schedule.title_id, 'info', `ğŸ“¤ Uploading to YouTube...`);
    updatePipelineStatus(uploadPipelineId, 'running');

    const uploadResult = await uploadToYouTube(videoResult.videoId, schedule, uploadPipelineId, maxRetry);

    if (!uploadResult.success) {
      throw new Error(`YouTube upload failed: ${uploadResult.error}`);
    }

    updatePipelineStatus(uploadPipelineId, 'completed');

    // video_schedules í…Œì´ë¸”ì— youtube_upload_id ì €ì¥
    const dbUpdateUpload = new Database(dbPath);
    dbUpdateUpload.prepare(`UPDATE video_schedules SET youtube_upload_id = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?`)
      .run(uploadResult.uploadId, schedule.id);
    dbUpdateUpload.close();

    updateScheduleStatus(schedule.id, 'processing', { youtubeUploadId: uploadResult.uploadId });
    addPipelineLog(uploadPipelineId, 'info', `YouTube upload successful: ${uploadResult.videoUrl}`);
    addTitleLog(schedule.title_id, 'info', `âœ… YouTube upload successful: ${uploadResult.videoUrl}`);

    // ============================================================
    // Stage 4: ìœ íŠœë¸Œ í¼ë¸”ë¦¬ì‹œ (ì˜ˆì•½ ì‹œê°„ì— ê³µê°œ)
    // ============================================================
    addPipelineLog(publishPipelineId, 'info', `Scheduling YouTube publish`);
    addTitleLog(schedule.title_id, 'info', `ğŸ“… Scheduling publish...`);
    updatePipelineStatus(publishPipelineId, 'running');

    const publishResult = await scheduleYouTubePublish(uploadResult.uploadId!, schedule, publishPipelineId);

    if (!publishResult.success) {
      throw new Error(`YouTube publish scheduling failed: ${publishResult.error}`);
    }

    updatePipelineStatus(publishPipelineId, 'completed');
    updateScheduleStatus(schedule.id, 'completed');
    updateTitleStatus(schedule.title_id, 'completed');
    addPipelineLog(publishPipelineId, 'info', `Pipeline completed successfully!`);
    addTitleLog(schedule.title_id, 'info', `ğŸ‰ All done! Pipeline completed successfully!`);

    console.log(`âœ… [Pipeline] Successfully completed for schedule ${schedule.id}`);

  } catch (error: any) {
    console.error(`âŒ [Pipeline] Failed for schedule ${schedule.id}:`, error);

    // ì‹¤íŒ¨í•œ ë‹¨ê³„ ì°¾ê¸°
    const db = new Database(dbPath);
    const failedPipeline = db.prepare(`
      SELECT * FROM automation_pipelines
      WHERE schedule_id = ? AND status = 'running'
      ORDER BY created_at DESC
      LIMIT 1
    `).get(schedule.id) as any;
    db.close();

    if (failedPipeline) {
      updatePipelineStatus(failedPipeline.id, 'failed', error.message);
      addPipelineLog(failedPipeline.id, 'error', `Pipeline failed: ${error.message}`);
    }

    updateScheduleStatus(schedule.id, 'failed');
    updateTitleStatus(schedule.title_id, 'failed');
    addTitleLog(schedule.title_id, 'error', `âŒ Pipeline failed: ${error.message}`);

    // ì—ëŸ¬ ì´ë©”ì¼ ì „ì†¡
    await sendAutomationErrorEmail(
      schedule.id,
      'pipeline_execution',
      error.message,
      { schedule, failedStage: failedPipeline?.stage }
    );
  }
}

// ============================================================
// ê°œë³„ Stage í•¨ìˆ˜ë“¤
// ============================================================

// Stage 1: ëŒ€ë³¸ ìƒì„± (ì¬ì‹œë„ ë¡œì§ ì œê±°)
async function generateScript(schedule: any, pipelineId: string, maxRetry: number) {
  console.log('ğŸ” [SCHEDULER] generateScript called with schedule:', {
    id: schedule.id,
    title: schedule.title,
    user_id: schedule.user_id,
    hasUserId: !!schedule.user_id
  });
  console.log('ğŸ” [SCHEDULER] Full schedule keys:', Object.keys(schedule));
  console.log('ğŸ” [SCHEDULER] schedule.product_data exists?:', !!schedule.product_data);
  console.log('ğŸ” [SCHEDULER] schedule.type:', schedule.type);

  try {
    addPipelineLog(pipelineId, 'info', `ğŸ“ ëŒ€ë³¸ ìƒì„± ì‹œì‘...`);
    addTitleLog(schedule.title_id, 'info', `ğŸ“ ëŒ€ë³¸ ìƒì„± ì‹œì‘...`);

    // product_dataê°€ ìˆìœ¼ë©´ JSON íŒŒì‹±
    let productInfo = undefined;
    if (schedule.product_data) {
      try {
        productInfo = JSON.parse(schedule.product_data);
        console.log('ğŸ›ï¸ [SCHEDULER] Product data found:', productInfo);
        console.log('  - title:', productInfo?.title);
        console.log('  - thumbnail:', productInfo?.thumbnail);
        console.log('  - product_link:', productInfo?.product_link);
        console.log('  - description:', productInfo?.description);
      } catch (e) {
        console.error('âŒ [SCHEDULER] Failed to parse product_data:', e);
        console.error('  - Raw product_data:', schedule.product_data);
      }
    } else {
      console.warn(`âš ï¸ [SCHEDULER] No product_data for type: ${schedule.type}`);
    }

    const requestBody = {
      title: schedule.title,
      type: schedule.type,
      productUrl: schedule.product_url,
      productInfo: productInfo || null, // undefined ëŒ€ì‹  null ì‚¬ìš© (JSON.stringifyì—ì„œ ì œì™¸ë˜ì§€ ì•Šë„ë¡)
      model: schedule.model || 'claude',
      useClaudeLocal: schedule.script_mode !== 'api',
      userId: schedule.user_id,
      category: schedule.category
    };

    console.log('ğŸ” [SCHEDULER] Request body:', JSON.stringify(requestBody, null, 2));
    console.log(`  - productInfo ì „ë‹¬: ${requestBody.productInfo ? 'YES âœ…' : 'NO âŒ'}`);

    // API ë°©ì‹ìœ¼ë¡œ ëŒ€ë³¸ ìƒì„± (ë‚´ë¶€ ìš”ì²­ í—¤ë” í¬í•¨)
    console.log('ğŸ“¤ [SCHEDULER] Calling /api/scripts/generate...');
    const response = await fetch(`http://localhost:${process.env.PORT || 3000}/api/scripts/generate`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Internal-Request': 'automation-system'
      },
      body: JSON.stringify(requestBody)
    });

    console.log(`ğŸ“¥ [SCHEDULER] Script API response status: ${response.status}`);

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`âŒ [SCHEDULER] Script API error response: ${errorText}`);
      let error;
      try {
        error = JSON.parse(errorText);
      } catch (e) {
        throw new Error(`Script generation failed: ${errorText}`);
      }
      throw new Error(error.error || 'Script generation failed');
    }

    const data = await response.json();
    console.log('âœ… [SCHEDULER] Script API response data:', JSON.stringify(data, null, 2));

    // taskIdê°€ ë°˜í™˜ë˜ë©´ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    if (data.taskId) {
      addPipelineLog(pipelineId, 'info', `Script generation job started: ${data.taskId}`);

      // ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 10ë¶„)
      const maxWaitTime = 10 * 60 * 1000;
      const startTime = Date.now();
      let lastProgress = 0; // ë§ˆì§€ë§‰ ì§„í–‰ë¥  ì¶”ì 

      while (Date.now() - startTime < maxWaitTime) {
        await new Promise(resolve => setTimeout(resolve, 5000)); // 5ì´ˆë§ˆë‹¤ ì²´í¬

        const elapsed = Math.floor((Date.now() - startTime) / 1000);
        console.log(`ğŸ” [SCHEDULER] Checking script status for ${data.taskId}... (ê²½ê³¼ì‹œê°„: ${elapsed}ì´ˆ)`);
        const statusRes = await fetch(`http://localhost:${process.env.PORT || 3000}/api/scripts/status/${data.taskId}`);

        console.log(`ğŸ“¥ [SCHEDULER] Status API response: ${statusRes.status}`);

        if (!statusRes.ok) {
          const errorText = await statusRes.text();
          console.error(`âŒ [SCHEDULER] Status API failed: ${statusRes.status}, Response: ${errorText}`);
          continue;
        }

        const statusData = await statusRes.json();
        console.log(`ğŸ“Š [SCHEDULER] Script Status Response:`, JSON.stringify(statusData, null, 2));

        if (statusData.status === 'completed') {
          addPipelineLog(pipelineId, 'info', `Script generation completed: ${data.taskId}`);
          addTitleLog(schedule.title_id, 'info', 'âœ… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ!');
          console.log(`âœ… [SCHEDULER] Script generation completed!`);
          return { success: true, scriptId: data.taskId };
        } else if (statusData.status === 'failed') {
          console.error(`âŒ [SCHEDULER] Script generation failed: ${statusData.error}`);
          throw new Error(`Script generation failed: ${statusData.error}`);
        }

        // ì§„í–‰ ìƒí™© ë¡œê·¸ (progressê°€ ë³€ê²½ë  ë•Œë§Œ)
        if (statusData.progress && statusData.progress !== lastProgress) {
          lastProgress = statusData.progress;
          const msg = `ğŸ“ ëŒ€ë³¸ ìƒì„± ì¤‘... ${statusData.progress}%`;
          addPipelineLog(pipelineId, 'info', msg);
          addTitleLog(schedule.title_id, 'info', msg);
        }
      }

      throw new Error('Script generation timeout (10ë¶„ ì´ˆê³¼)');
    }

    return { success: true, scriptId: data.taskId || data.scriptId };

  } catch (error: any) {
    const errorMsg = error.message || 'Unknown error';
    addPipelineLog(pipelineId, 'error', `âŒ ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: ${errorMsg}`);
    addTitleLog(schedule.title_id, 'error', `âŒ ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: ${errorMsg}`);
    console.error(`âŒ [SCHEDULER] Script generation failed:`, error.message);
    return { success: false, error: errorMsg };
  }
}

// Stage 2: ì˜ìƒ ìƒì„± (ì¬ì‹œë„ ë¡œì§ ì œê±°)
async function generateVideo(scriptId: string, pipelineId: string, maxRetry: number, titleId: string, schedule: any) {
  const settings = getAutomationSettings();
  const mediaMode = schedule.media_mode || settings.media_generation_mode || 'upload';

  try {
    addPipelineLog(pipelineId, 'info', `ğŸ¬ ì˜ìƒ ìƒì„± ì‹œì‘... (mode: ${mediaMode})`);
    addTitleLog(titleId, 'info', `ğŸ¬ ì˜ìƒ ìƒì„± ì‹œì‘...`);

    // DBì—ì„œ ëŒ€ë³¸ ì¡°íšŒ
    const db = new Database(dbPath);
    const content = db.prepare(`
      SELECT id, title, content, type, user_id
      FROM contents
      WHERE id = ? AND type = 'script'
    `).get(scriptId) as any;
    db.close();

    if (!content) {
      throw new Error(`Script not found: ${scriptId}`);
    }

    if (!content.user_id) {
      throw new Error(`Script ${scriptId} has no user_id`);
    }

    // content íŒŒì‹±
    let scriptData;
    try {
      let contentStr = typeof content.content === 'string' ? content.content : JSON.stringify(content.content);

      // JSON ì •ë¦¬
      contentStr = contentStr.trim();
      if (contentStr.startsWith('JSON')) {
        contentStr = contentStr.substring(4).trim();
      }
      const jsonStart = contentStr.indexOf('{');
      if (jsonStart > 0) {
        contentStr = contentStr.substring(jsonStart);
      }

      scriptData = JSON.parse(contentStr);
    } catch (e: any) {
      throw new Error(`Failed to parse script content: ${e.message}`);
    }

    // story.json ìƒì„±
    const storyJson = {
      ...scriptData,
      scenes: scriptData.scenes || []
    };

    // ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ í™•ì¸
    const scriptFolderPath = path.join(process.cwd(), '..', 'trend-video-backend', 'input', `project_${scriptId}`);
    let hasUploadedImages = false;
    let hasUploadedVideos = false;
    let imageFiles: string[] = [];
    let videoFiles: string[] = [];
    if (fs.existsSync(scriptFolderPath)) {
      const files = fs.readdirSync(scriptFolderPath);
      imageFiles = files.filter(f => /\.(png|jpg|jpeg|webp)$/i.test(f));
      videoFiles = files.filter(f => /\.(mp4|mov|avi|mkv)$/i.test(f));
      hasUploadedImages = imageFiles.length > 0;
      hasUploadedVideos = videoFiles.length > 0;
      if (hasUploadedImages || hasUploadedVideos) {
        console.log(`[Scheduler] Found ${imageFiles.length} image(s) and ${videoFiles.length} video(s) in ${scriptFolderPath}`);
      }
    }

    // ì”¬ ê°œìˆ˜ í™•ì¸
    const sceneCount = storyJson.scenes?.length || 0;
    const totalMediaCount = imageFiles.length + videoFiles.length;

    // ì¸ë„¤ì¼ ë¶„ë¦¬ ë¡œì§: ì˜ìƒ+ì´ë¯¸ì§€ê°€ í•¨ê»˜ ìˆê³ , ì´ ë¯¸ë””ì–´ê°€ ì”¬ë³´ë‹¤ ë§ì„ ë•Œë§Œ ì²« ì´ë¯¸ì§€ë¥¼ ì¸ë„¤ì¼ë¡œ ì‚¬ìš©
    let useThumbnailFromFirstImage = false;
    if (hasUploadedImages && hasUploadedVideos && totalMediaCount > sceneCount) {
      // íŒŒì¼ì„ scene ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬ (scene_0, scene_1, ...)
      const sortedImages = imageFiles.sort((a, b) => {
        const aMatch = a.match(/scene_(\d+)/);
        const bMatch = b.match(/scene_(\d+)/);
        const aNum = aMatch ? parseInt(aMatch[1]) : 999;
        const bNum = bMatch ? parseInt(bMatch[1]) : 999;
        return aNum - bNum;
      });

      // ì²« ë²ˆì§¸ íŒŒì¼ì´ scene_0ì´ê³  ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
      const firstFile = sortedImages[0];
      if (firstFile && /scene_0.*\.(png|jpg|jpeg|webp)$/i.test(firstFile)) {
        useThumbnailFromFirstImage = true;
        console.log(`\nğŸ“Œ [SCHEDULER] ì¸ë„¤ì¼ ë¶„ë¦¬ ì¡°ê±´ ë§Œì¡±: ì˜ìƒ+ì´ë¯¸ì§€ ìˆê³  ë¯¸ë””ì–´(${totalMediaCount}) > ì”¬(${sceneCount})`);
        console.log(`   ğŸ–¼ï¸ ì¸ë„¤ì¼: ${firstFile}`);
        console.log(`   ğŸ“¹ ì”¬ ë¯¸ë””ì–´: ${totalMediaCount - 1}ê°œ (${firstFile} ì œì™¸)`);
      }
    } else {
      console.log(`\nğŸ“Œ [SCHEDULER] ì¸ë„¤ì¼ ë¶„ë¦¬ ì•ˆ í•¨:`);
      if (!hasUploadedImages || !hasUploadedVideos) {
        console.log(`   - ì˜ìƒ+ì´ë¯¸ì§€ ë¯¸í¬í•¨ (ì˜ìƒ: ${hasUploadedVideos}, ì´ë¯¸ì§€: ${hasUploadedImages})`);
      }
      if (totalMediaCount <= sceneCount) {
        console.log(`   - ë¯¸ë””ì–´(${totalMediaCount}) â‰¤ ì”¬(${sceneCount})`);
      }
      console.log(`   â†’ ëª¨ë“  ë¯¸ë””ì–´ë¥¼ ì”¬ì— ì‚¬ìš©`);
    }

    // ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„¤ì • (ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
    const imageSource = (mediaMode === 'upload' || hasUploadedImages) ? 'none' : mediaMode;

    // ì´ë¯¸ì§€ ëª¨ë¸ ì„¤ì • (imagen3 -> imagen3, ë‚˜ë¨¸ì§€ëŠ” dalle3)
    const imageModel = mediaMode === 'imagen3' ? 'imagen3' : 'dalle3';

    // ë¹„ë””ì˜¤ í¬ë§·
    const videoType = schedule.type || scriptData.metadata?.genre || 'shortform';

    // JSONìœ¼ë¡œ ì „ì†¡ (ë‚´ë¶€ ìš”ì²­)
    const requestBody: any = {
      storyJson,
      userId: content.user_id,
      imageSource,
      imageModel,
      videoFormat: videoType,
      ttsVoice: 'ko-KR-SoonBokNeural',
      title: content.title,
      scriptId,  // ìë™í™”ìš©: ì´ë¯¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
      useThumbnailFromFirstImage  // ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ì¸ë„¤ì¼ë¡œ ì‚¬ìš© ì—¬ë¶€
    };

    // ============================================================
    // ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: ê°™ì€ source_content_idë¡œ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ jobì´ ìˆëŠ”ì§€ í™•ì¸
    // ============================================================
    const dbCheck = new Database(dbPath);
    let jobId: string | undefined;
    let shouldCallApi = true;

    const existingJob = dbCheck.prepare(`
      SELECT id, status, title
      FROM jobs
      WHERE source_content_id = ?
        AND status IN ('pending', 'processing')
      ORDER BY created_at DESC
      LIMIT 1
    `).get(scriptId) as any;

    dbCheck.close();

    if (existingJob) {
      console.log(`ğŸ” [DUPLICATE CHECK] Found existing job: ${existingJob.id} (status: ${existingJob.status})`);
      addPipelineLog(pipelineId, 'info', `âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ë°œê²¬: ${existingJob.id}`);
      addTitleLog(titleId, 'info', `âš ï¸ ê¸°ì¡´ ì‘ì—…ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤: ${existingJob.id}`);

      jobId = existingJob.id;
      shouldCallApi = false;
    } else {
      // ìƒˆë¡œìš´ job ìƒì„±ì€ APIì—ì„œ ì²˜ë¦¬ (fresh created_at íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ)
      console.log(`âœ… [DUPLICATE CHECK] No existing job found, will create new job via API`);
      addPipelineLog(pipelineId, 'info', `ğŸ“ APIë¥¼ í†µí•´ ìƒˆ Job ìƒì„± ì˜ˆì •`);
      shouldCallApi = true;
    }

    console.log('ğŸ“¤ [SCHEDULER] Calling /api/generate-video-upload...');
    console.log('ğŸ” [SCHEDULER] Request body:', {
      scriptId,
      userId: content.user_id,
      imageSource,
      imageModel,
      videoFormat: videoType
    });

    let response: Response | null = null;
    let data: any = null;

    // ê¸°ì¡´ jobì´ ì—†ì„ ë•Œë§Œ API í˜¸ì¶œ
    if (shouldCallApi) {
      // APIê°€ fresh created_at íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ìƒˆ jobì„ ìƒì„±í•˜ë„ë¡ jobIdë¥¼ ì „ë‹¬í•˜ì§€ ì•ŠìŒ
      // (ë©”ì¸ í˜ì´ì§€ì™€ ë™ì¼í•œ ë°©ì‹)

      // /api/generate-video-upload í˜¸ì¶œ
      response = await fetch(`http://localhost:${process.env.PORT || 3000}/api/generate-video-upload`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-Internal-Request': 'automation-system'
        },
        body: JSON.stringify(requestBody)
      });

      console.log(`ğŸ“¥ [SCHEDULER] Video API response status: ${response.status}`);

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`âŒ [SCHEDULER] Video API error response: ${errorText}`);
        let error;
        try {
          error = JSON.parse(errorText);
        } catch (e) {
          throw new Error(`Video generation failed: ${errorText}`);
        }
        throw new Error(error.error || 'Video generation failed');
      }

      data = await response.json();
      console.log('âœ… [SCHEDULER] Video API response data:', JSON.stringify(data, null, 2));

      jobId = data.jobId;
    } else {
      // ê¸°ì¡´ job ì¬ì‚¬ìš© - jobIdëŠ” ì´ë¯¸ ì„¤ì •ë¨
      console.log(`â™»ï¸ [SCHEDULER] Reusing existing job: ${jobId}`);
    }

    // ì‘ì—…ì´ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ë˜ëŠ” ê²½ìš° í´ë§
    if (jobId) {
      addPipelineLog(pipelineId, 'info', `Video generation job: ${jobId}`);

      // âœ… FIX: jobIdë¥¼ ì¦‰ì‹œ ì €ì¥í•˜ì—¬ ì§„í–‰ ì¤‘ ë¡œê·¸ ì¡°íšŒ ê°€ëŠ¥í•˜ë„ë¡
      const dbSaveJob = new Database(dbPath);
      dbSaveJob.prepare(`UPDATE video_schedules SET video_id = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?`)
        .run(jobId, schedule.id);
      dbSaveJob.close();
      console.log(`âœ… [SCHEDULER] Saved video_id to schedule: ${jobId}`);

      // ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 30ë¶„)
      const maxWaitTime = 30 * 60 * 1000; // 30ë¶„
      const startTime = Date.now();
      let lastProgress = 0; // ë§ˆì§€ë§‰ ì§„í–‰ë¥  ì¶”ì 

      while (Date.now() - startTime < maxWaitTime) {
        await new Promise(resolve => setTimeout(resolve, 5000)); // 5ì´ˆë§ˆë‹¤ ì²´í¬

        // ì¤‘ì§€ ìš”ì²­ í™•ì¸ (DBì—ì„œ schedule ìƒíƒœ ì²´í¬)
        const db = new Database(dbPath);
        const pipeline = db.prepare('SELECT status FROM automation_pipelines WHERE id = ?').get(pipelineId) as any;
        const schedule = db.prepare(`
          SELECT vs.status
          FROM video_schedules vs
          JOIN automation_pipelines ap ON ap.schedule_id = vs.id
          WHERE ap.id = ?
        `).get(pipelineId) as any;
        db.close();

        if (pipeline && pipeline.status === 'failed') {
          console.log(`ğŸ›‘ [SCHEDULER] Pipeline ${pipelineId} failed`);
          throw new Error('ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤');
        }

        if (schedule && schedule.status === 'cancelled') {
          console.log(`ğŸ›‘ [SCHEDULER] Schedule for pipeline ${pipelineId} was cancelled by user`);
          throw new Error('ì‘ì—…ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤');
        }

        const elapsed = Math.floor((Date.now() - startTime) / 1000);
        console.log(`ğŸ” [SCHEDULER] Checking video status for ${jobId}... (ê²½ê³¼ì‹œê°„: ${elapsed}ì´ˆ)`);

        const statusRes = await fetch(`http://localhost:${process.env.PORT || 3000}/api/generate-video-upload?jobId=${jobId}`);
        console.log(`ğŸ“¥ [SCHEDULER] Video Status API response: ${statusRes.status}`);

        if (!statusRes.ok) {
          const errorText = await statusRes.text();
          console.error(`âŒ [SCHEDULER] Video Status API failed: ${statusRes.status}, Response: ${errorText}`);
          continue;
        }

        const statusData = await statusRes.json();
        console.log(`ğŸ“Š [SCHEDULER] Video Status Response:`, JSON.stringify(statusData, null, 2));

        if (statusData.status === 'completed') {
          addPipelineLog(pipelineId, 'info', `Video generation completed: ${statusData.videoId}`);
          addTitleLog(titleId, 'info', 'âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ!');
          console.log(`âœ… [SCHEDULER] Video generation completed!`);
          return { success: true, videoId: statusData.videoId };
        } else if (statusData.status === 'failed') {
          console.error(`âŒ [SCHEDULER] Video generation failed: ${statusData.error}`);
          throw new Error(`Video generation failed: ${statusData.error}`);
        }

        // ì§„í–‰ ìƒí™© ë¡œê·¸ (progressê°€ ë³€ê²½ë  ë•Œë§Œ)
        if (statusData.progress && statusData.progress !== lastProgress) {
          lastProgress = statusData.progress;
          const msg = `ğŸ¬ ì˜ìƒ ìƒì„± ì¤‘... ${statusData.progress}%`;
          console.log(`ğŸ“ˆ [SCHEDULER] Video Progress: ${statusData.progress}`);
          addPipelineLog(pipelineId, 'info', msg);
          addTitleLog(titleId, 'info', msg);
        }
      }

      throw new Error('Video generation timeout (30ë¶„ ì´ˆê³¼)');
    }

    // ì¦‰ì‹œ ì™„ë£Œë˜ëŠ” ê²½ìš° (ê±°ì˜ ì—†ì§€ë§Œ ë°©ì–´ ì½”ë“œ)
    return { success: true, videoId: data?.videoId || jobId };

  } catch (error: any) {
    const errorMsg = error.message || 'Unknown error';
    addPipelineLog(pipelineId, 'error', `âŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: ${errorMsg}`);
    addTitleLog(titleId, 'error', `âŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: ${errorMsg}`);
    console.error(`âŒ [SCHEDULER] Video generation failed:`, error.message);
    return { success: false, error: errorMsg };
  }
}

// Stage 3: ìœ íŠœë¸Œ ì—…ë¡œë“œ
async function uploadToYouTube(videoId: string, schedule: any, pipelineId: string, maxRetry: number) {
  try {
    addPipelineLog(pipelineId, 'info', `Uploading to YouTube`);
    console.log(`ğŸ” [YOUTUBE UPLOAD] videoId: ${videoId}`);

    // jobs í…Œì´ë¸”ì—ì„œ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ
    const db = new Database(dbPath);
    const job = db.prepare(`SELECT * FROM jobs WHERE id = ?`).get(videoId) as any;
    db.close();

    console.log(`ğŸ” [YOUTUBE UPLOAD] job found:`, {
      hasJob: !!job,
      jobId: job?.id,
      jobVideoPath: job?.video_path,
      jobTitle: job?.title,
      jobStatus: job?.status
    });

    if (!job || !job.video_path) {
      addPipelineLog(pipelineId, 'error', `Video file not found in jobs table. videoId: ${videoId}, hasJob: ${!!job}, hasVideoPath: ${!!job?.video_path}`);
      throw new Error('Video file not found');
    }

    // ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (video_pathëŠ” ì´ë¯¸ ì ˆëŒ€ ê²½ë¡œ)
    const videoPath = job.video_path;
    console.log(`ğŸ” [YOUTUBE UPLOAD] videoPath: ${videoPath}`);

    // íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    const fs = require('fs');
    const fileExists = fs.existsSync(videoPath);
    console.log(`ğŸ” [YOUTUBE UPLOAD] file exists: ${fileExists}`);

    if (!fileExists) {
      addPipelineLog(pipelineId, 'error', `Video file not found at path: ${videoPath}`);
      throw new Error(`Video file not found at path: ${videoPath}`);
    }

    // ğŸ”’ ì¤‘ë³µ ì²´í¬: ì´ë¯¸ ì—…ë¡œë“œëœ ì˜ìƒì¸ì§€ í™•ì¸
    const dbUploadCheck = new Database(dbPath);
    const existingUpload = dbUploadCheck.prepare(`
      SELECT id, video_url FROM youtube_uploads
      WHERE job_id = ?
        AND video_url IS NOT NULL
        AND video_url != ''
      LIMIT 1
    `).get(videoId) as { id: string; video_url: string } | undefined;
    dbUploadCheck.close();

    if (existingUpload) {
      console.warn(`âš ï¸ [YOUTUBE] ì¤‘ë³µ ì—…ë¡œë“œ ë°©ì§€: videoId=${videoId}ëŠ” ì´ë¯¸ ì—…ë¡œë“œë¨ (${existingUpload.video_url})`);
      addPipelineLog(pipelineId, 'info', `âš ï¸ ì´ë¯¸ ì—…ë¡œë“œëœ ì˜ìƒì…ë‹ˆë‹¤: ${existingUpload.video_url}`);

      // ìŠ¤ì¼€ì¤„ ìƒíƒœ ì—…ë°ì´íŠ¸
      const dbStatus = new Database(dbPath);
      dbStatus.prepare(`
        UPDATE video_schedules
        SET status = 'completed', youtube_url = ?, updated_at = CURRENT_TIMESTAMP
        WHERE id = ?
      `).run(existingUpload.video_url, schedule.id);
      dbStatus.close();

      return; // ì¤‘ë³µ ì—…ë¡œë“œ ë°©ì§€
    }

    // YouTube API í˜¸ì¶œ
    const privacyValue = schedule.youtube_privacy || 'public';
    addPipelineLog(pipelineId, 'info', `Calling YouTube upload API for video: ${job.title}`);
    addPipelineLog(pipelineId, 'info', `YouTube ê³µê°œ ì„¤ì •: ${privacyValue} (DBê°’: ${schedule.youtube_privacy})`);

    const uploadResponse = await fetch(`http://localhost:${process.env.PORT || 3000}/api/youtube/upload`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Internal-Request': 'automation-system'
      },
      body: JSON.stringify({
        videoPath,
        title: job.title || schedule.title,
        description: '', // ë¹ˆ ë¬¸ìì—´ (ìƒí’ˆì •ë³´ ëŒ€ë³¸ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì¶”ê°€ë  ì˜ˆì •)
        tags: schedule.tags ? schedule.tags.split(',').map((t: string) => t.trim()) : [],
        privacy: privacyValue, // ì‚¬ìš©ì ì„¤ì • ìš°ì„ , ì—†ìœ¼ë©´ public
        channelId: schedule.channel,
        jobId: videoId,
        publishAt: schedule.youtube_publish_time,
        userId: schedule.user_id, // ë‚´ë¶€ ìš”ì²­ìš© userId ì „ë‹¬
        type: job.type // ìƒí’ˆ íƒ€ì… ì „ë‹¬ (ìƒí’ˆì •ë³´ ëŒ€ë³¸ ê²€ìƒ‰ìš©)
      })
    });

    addPipelineLog(pipelineId, 'info', `YouTube upload API response: ${uploadResponse.status}`);

    if (!uploadResponse.ok) {
      const errorText = await uploadResponse.text();
      addPipelineLog(pipelineId, 'error', `YouTube upload failed: ${errorText}`);
      throw new Error(`YouTube upload failed: ${errorText}`);
    }

    const uploadData = await uploadResponse.json();

    if (!uploadData.success) {
      throw new Error(uploadData.error || 'YouTube upload failed');
    }

    addPipelineLog(pipelineId, 'info', `âœ… YouTube upload successful: ${uploadData.videoUrl}`);

    // video_schedules í…Œì´ë¸”ì— youtube_upload_idì™€ youtube_url ì—…ë°ì´íŠ¸
    // YouTube APIì—ì„œ ì´ë¯¸ youtube_uploads í…Œì´ë¸”ì— ì €ì¥í–ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì €ì¥í•˜ì§€ ì•ŠìŒ
    if (uploadData.uploadId || uploadData.videoUrl) {
      const uploadDb = new Database(dbPath);
      uploadDb.prepare(`
        UPDATE video_schedules
        SET youtube_upload_id = ?, youtube_url = ?, updated_at = CURRENT_TIMESTAMP
        WHERE id = ?
      `).run(uploadData.uploadId || null, uploadData.videoUrl || null, schedule.id);
      uploadDb.close();
      console.log(`âœ… video_schedules ì—…ë°ì´íŠ¸: youtube_upload_id = ${uploadData.uploadId}, youtube_url = ${uploadData.videoUrl}`);
    }

    return {
      success: true,
      uploadId: uploadData.videoId,
      videoUrl: uploadData.videoUrl
    };

  } catch (error: any) {
    addPipelineLog(pipelineId, 'error', `YouTube upload failed: ${error.message}`);
    addTitleLog(schedule.title_id, 'error', `âŒ YouTube upload failed: ${error.message}`);
    return { success: false, error: error.message };
  }
}

// Stage 4: ìœ íŠœë¸Œ í¼ë¸”ë¦¬ì‹œ ì˜ˆì•½
async function scheduleYouTubePublish(uploadId: string, schedule: any, pipelineId: string) {
  try {
    addPipelineLog(pipelineId, 'info', `Scheduling YouTube publish for: ${schedule.youtube_publish_time || 'immediate'}`);

    // youtube_publish_timeì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì˜ˆì•½, ì—†ìœ¼ë©´ ì¦‰ì‹œ ê³µê°œ
    if (schedule.youtube_publish_time) {
      addPipelineLog(pipelineId, 'info', `Video will be published at: ${schedule.youtube_publish_time}`);
      addTitleLog(schedule.title_id, 'info', `ğŸ“… ì˜ˆì•½ë¨: ${new Date(schedule.youtube_publish_time).toLocaleString('ko-KR')}`);
    } else {
      addPipelineLog(pipelineId, 'info', `Video set to immediate publish`);
      addTitleLog(schedule.title_id, 'info', `âœ… ì¦‰ì‹œ ê³µê°œ ì„¤ì •ë¨`);
    }

    return { success: true };

  } catch (error: any) {
    addPipelineLog(pipelineId, 'error', `Failed to schedule publish: ${error.message}`);
    return { success: false, error: error.message };
  }
}

// ============================================================
// ì—ëŸ¬ ì•Œë¦¼ í•¨ìˆ˜
// ============================================================

async function sendAutomationErrorEmail(
  scheduleId: string,
  stage: string,
  errorMessage: string,
  context: any
) {
  try {
    const settings = getAutomationSettings();
    const alertEmail = settings.alert_email || 'moony75@gmail.com';

    const subject = `[ìë™í™” ì‹¤íŒ¨] ${stage} - ${scheduleId}`;
    const html = `
      <h2>ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ì•Œë¦¼</h2>
      <p><strong>ìŠ¤ì¼€ì¤„ ID:</strong> ${scheduleId}</p>
      <p><strong>ì‹¤íŒ¨ ë‹¨ê³„:</strong> ${stage}</p>
      <p><strong>ì—ëŸ¬ ë©”ì‹œì§€:</strong> ${errorMessage}</p>
      <p><strong>ì œëª©:</strong> ${context.schedule?.title || 'N/A'}</p>
      <p><strong>íƒ€ì…:</strong> ${context.schedule?.type || 'N/A'}</p>
      <p><strong>ì˜ˆì•½ ì‹œê°„:</strong> ${context.schedule?.scheduled_time || 'N/A'}</p>
      <hr>
      <h3>Context:</h3>
      <pre>${JSON.stringify(context, null, 2)}</pre>
      <hr>
      <p><em>ì´ ì´ë©”ì¼ì€ ìë™í™” ì‹œìŠ¤í…œì—ì„œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.</em></p>
    `;

    await sendErrorEmail(alertEmail, subject, html);
    console.log(`âœ… Error email sent to ${alertEmail}`);

  } catch (error) {
    console.error('Failed to send error email:', error);
  }
}

// ============================================================
// ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸
// ============================================================

export function getSchedulerStatus() {
  return {
    isRunning: schedulerInterval !== null,
    settings: getAutomationSettings()
  };
}

// ============================================================
// ì´ë¯¸ì§€ ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ í™•ì¸
// ============================================================

async function checkWaitingForUploadSchedules() {
  try {
    const waitingSchedules = getWaitingForUploadSchedules();

    if (waitingSchedules.length === 0) {
      return;
    }

    console.log(`[Scheduler] Checking ${waitingSchedules.length} schedule(s) waiting for upload`);

    for (const schedule of waitingSchedules) {
      try {
        // script_idê°€ ìˆëŠ”ì§€ í™•ì¸
        if (!schedule.script_id) {
          console.log(`[Scheduler] Schedule ${schedule.id} has no script_id, skipping`);
          continue;
        }

        // ìŠ¤í¬ë¦½íŠ¸ í´ë”ì—ì„œ ì´ë¯¸ì§€ í™•ì¸
        const fs = require('fs');
        const scriptFolderPath = path.join(process.cwd(), '..', 'trend-video-backend', 'input', `project_${schedule.script_id}`);

        // í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if (!fs.existsSync(scriptFolderPath)) {
          console.log(`[Scheduler] Script folder not found: ${scriptFolderPath}`);
          continue;
        }

        // ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸ (scene_*.png, scene_*.jpg, scene_*.webp ë“±)
        const files = fs.readdirSync(scriptFolderPath);
        const imageFiles = files.filter((file: string) =>
          /scene_\d+.*\.(png|jpg|jpeg|webp|gif)$/i.test(file)
        );

        if (imageFiles.length === 0) {
          console.log(`[Scheduler] No images found in ${scriptFolderPath}, waiting...`);
          continue;
        }

        console.log(`[Scheduler] Found ${imageFiles.length} image(s) in ${scriptFolderPath}`);
        console.log(`[Scheduler] Images: ${imageFiles.join(', ')}`);

        // ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìœ¼ë¯€ë¡œ processing ìƒíƒœë¡œ ë³€ê²½í•˜ê³  video ë‹¨ê³„ ì‹œì‘
        console.log(`[Scheduler] âœ… ${imageFiles.length} images found for ${schedule.id}`);
        addPipelineLog(schedule.id, 'info', `âœ… ${imageFiles.length}ê°œ ì´ë¯¸ì§€ ì—…ë¡œë“œ í™•ì¸ë¨, ì˜ìƒ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤`);
        addTitleLog(schedule.title_id, 'info', `âœ… ì´ë¯¸ì§€ ${imageFiles.length}ê°œ ì—…ë¡œë“œ í™•ì¸ë¨! ì˜ìƒ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...`);

        updateScheduleStatus(schedule.id, 'processing', { imagesReady: true });

        // video ë‹¨ê³„ ì‹œì‘ (ë¹„ë™ê¸°)
        // ê¸°ì¡´ì— ìƒì„±ëœ video pipeline ID ì°¾ê¸°
        const db = new Database(dbPath);
        const videoPipeline = db.prepare(`
          SELECT id FROM automation_pipelines
          WHERE schedule_id = ? AND stage = 'video'
          LIMIT 1
        `).get(schedule.id) as any;
        db.close();

        const videoPipelineId = videoPipeline?.id || (schedule.id + '_video');
        console.log(`[Scheduler] Using video pipeline ID: ${videoPipelineId}`);
        console.log(`[Scheduler] Starting resumeVideoGeneration for ${schedule.id}`);

        resumeVideoGeneration(schedule, videoPipelineId).catch((error: any) => {
          console.error(`[Scheduler] Failed to resume video generation for ${schedule.id}:`, error);
          console.error(`[Scheduler] Error stack:`, error.stack);
          addPipelineLog(videoPipelineId, 'error', `Video generation failed: ${error.message}`);
          addTitleLog(schedule.title_id, 'error', `âŒ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: ${error.message}`);
          updatePipelineStatus(videoPipelineId, 'failed');
          updateScheduleStatus(schedule.id, 'failed');
        });

      } catch (error: any) {
        console.error(`[Scheduler] Error checking schedule ${schedule.id}:`, error);
      }
    }

  } catch (error: any) {
    console.error('[Scheduler] Error in checkWaitingForUploadSchedules:', error);
  }
}

// ì˜ìƒ ìƒì„± ì™„ë£Œë˜ì–´ ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ ì²´í¬ ë° ì—…ë¡œë“œ ì‹œì‘
async function checkReadyToUploadSchedules() {
  try {
    const db = new Database(dbPath);
    const readySchedules = db.prepare(`
      SELECT s.*, t.title, t.type, t.user_id
      FROM video_schedules s
      JOIN video_titles t ON s.title_id = t.id
      WHERE s.video_id IS NOT NULL
        AND s.youtube_url IS NULL
        AND s.status = 'processing'
      ORDER BY s.created_at ASC
      LIMIT 5
    `).all() as any[];
    db.close();

    if (readySchedules.length === 0) {
      return;
    }

    console.log(`[Scheduler] Found ${readySchedules.length} schedule(s) ready for upload`);

    for (const schedule of readySchedules) {
      try {
        console.log(`[Scheduler] Starting upload for schedule ${schedule.id}, video: ${schedule.video_id}`);

        // Upload pipeline ì°¾ê¸°
        const dbUpload = new Database(dbPath);
        const uploadPipeline = dbUpload.prepare(`
          SELECT id, status FROM automation_pipelines
          WHERE schedule_id = ? AND stage = 'upload'
          LIMIT 1
        `).get(schedule.id) as any;
        dbUpload.close();

        if (!uploadPipeline) {
          console.log(`[Scheduler] No upload pipeline found for ${schedule.id}, skipping`);
          continue;
        }

        // ì´ë¯¸ runningì´ê±°ë‚˜ completedë©´ ìŠ¤í‚µ
        if (uploadPipeline.status === 'running' || uploadPipeline.status === 'completed') {
          console.log(`[Scheduler] Upload pipeline already ${uploadPipeline.status} for ${schedule.id}, skipping`);
          continue;
        }

        const uploadPipelineId = uploadPipeline.id;
        const maxRetry = 3;

        // ë¹„ë™ê¸°ë¡œ ì—…ë¡œë“œ ì‹œì‘
        resumeUploadPipeline(schedule, uploadPipelineId, maxRetry).catch((error: any) => {
          console.error(`[Scheduler] Failed to upload for ${schedule.id}:`, error);
          addPipelineLog(uploadPipelineId, 'error', `Upload failed: ${error.message}`);
          addTitleLog(schedule.title_id, 'error', `âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: ${error.message}`);
          updatePipelineStatus(uploadPipelineId, 'failed');
          updateScheduleStatus(schedule.id, 'failed');
        });

      } catch (error: any) {
        console.error(`[Scheduler] Error checking ready schedule ${schedule.id}:`, error);
      }
    }

  } catch (error: any) {
    console.error('[Scheduler] Error in checkReadyToUploadSchedules:', error);
  }
}

// ì˜ìƒ ìƒì„± ì™„ë£Œ í›„ ì—…ë¡œë“œ ì¬ê°œ
async function resumeUploadPipeline(schedule: any, uploadPipelineId: string, maxRetry: number) {
  addPipelineLog(uploadPipelineId, 'info', `Starting YouTube upload for video: ${schedule.video_id}`);
  addTitleLog(schedule.title_id, 'info', `ğŸ“¤ YouTube ì—…ë¡œë“œ ì¤‘...`);
  updatePipelineStatus(uploadPipelineId, 'running');

  const uploadResult = await uploadToYouTube(schedule.video_id, schedule, uploadPipelineId, maxRetry);

  if (!uploadResult.success) {
    throw new Error(`YouTube upload failed: ${uploadResult.error}`);
  }

  updatePipelineStatus(uploadPipelineId, 'completed');

  // video_schedules í…Œì´ë¸”ì— youtube_url ì €ì¥
  const db = new Database(dbPath);
  db.prepare(`
    UPDATE video_schedules
    SET youtube_url = ?, updated_at = CURRENT_TIMESTAMP
    WHERE id = ?
  `).run(uploadResult.videoUrl, schedule.id);
  db.close();

  addPipelineLog(uploadPipelineId, 'info', `YouTube upload successful: ${uploadResult.videoUrl}`);
  addTitleLog(schedule.title_id, 'info', `âœ… YouTube ì—…ë¡œë“œ ì™„ë£Œ: ${uploadResult.videoUrl}`);

  // Publish ë‹¨ê³„
  const dbPublish = new Database(dbPath);
  const publishPipeline = dbPublish.prepare(`
    SELECT id FROM automation_pipelines
    WHERE schedule_id = ? AND stage = 'publish'
    LIMIT 1
  `).get(schedule.id) as any;
  dbPublish.close();

  const publishPipelineId = publishPipeline?.id || (schedule.id + '_publish');

  addPipelineLog(publishPipelineId, 'info', `Scheduling YouTube publish`);
  addTitleLog(schedule.title_id, 'info', `ğŸ“… í¼ë¸”ë¦¬ì‹œ ì˜ˆì•½ ì¤‘...`);
  updatePipelineStatus(publishPipelineId, 'running');

  const publishResult = await scheduleYouTubePublish(uploadResult.uploadId || '', schedule, publishPipelineId);

  if (!publishResult.success) {
    throw new Error(`YouTube publish scheduling failed: ${publishResult.error}`);
  }

  updatePipelineStatus(publishPipelineId, 'completed');
  updateScheduleStatus(schedule.id, 'completed');
  updateTitleStatus(schedule.title_id, 'completed');

  addPipelineLog(publishPipelineId, 'info', `Pipeline completed successfully`);
  addTitleLog(schedule.title_id, 'info', `ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!`);

  console.log(`[Scheduler] Upload pipeline completed for schedule ${schedule.id}`);
}

// ì´ë¯¸ì§€ ì—…ë¡œë“œ í›„ video ìƒì„± ì¬ê°œ
async function resumeVideoGeneration(schedule: any, videoPipelineId: string) {
  const maxRetry = 3;

  addPipelineLog(videoPipelineId, 'info', `Starting video generation from script: ${schedule.script_id}`);
  addTitleLog(schedule.title_id, 'info', `ğŸ¬ ì˜ìƒ ìƒì„± ì¤‘...`);
  updatePipelineStatus(videoPipelineId, 'running');

  const videoResult = await generateVideo(schedule.script_id, videoPipelineId, maxRetry, schedule.title_id, schedule);

  if (!videoResult.success) {
    throw new Error(`Video generation failed: ${videoResult.error}`);
  }

  if (!videoResult.videoId) {
    throw new Error('Video generation succeeded but videoId is missing');
  }

  console.log(`âœ… [SCHEDULER] Video generation completed, videoId: ${videoResult.videoId}, schedule: ${schedule.id}`);

  updatePipelineStatus(videoPipelineId, 'completed');

  // video_schedules í…Œì´ë¸”ì— video_id ì €ì¥ (ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆì§€ë§Œ ìµœì¢… í™•ì¸)
  const dbUpdateVideo = new Database(dbPath);
  dbUpdateVideo.prepare(`UPDATE video_schedules SET video_id = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?`)
    .run(videoResult.videoId, schedule.id);
  dbUpdateVideo.close();
  console.log(`âœ… [SCHEDULER] Video ID saved to schedule: ${videoResult.videoId} -> ${schedule.id}`);

  updateScheduleStatus(schedule.id, 'processing', { videoId: videoResult.videoId });
  addPipelineLog(videoPipelineId, 'info', `Video generated successfully: ${videoResult.videoId}`);
  addTitleLog(schedule.title_id, 'info', `âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ: ${videoResult.videoId}`);

  // ì´í›„ upload, publish ë‹¨ê³„ëŠ” ê¸°ì¡´ ë¡œì§ í™œìš©
  // TODO: uploadì™€ publish ë‹¨ê³„ë¥¼ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ì—¬ ì¬ì‚¬ìš©
  console.log(`[Scheduler] Video generation completed for ${schedule.id}, continuing with upload...`);

  // Upload ë‹¨ê³„ ì‹œì‘ - ê¸°ì¡´ pipeline ì°¾ê¸°
  const dbUpload = new Database(dbPath);
  const uploadPipeline = dbUpload.prepare(`
    SELECT id FROM automation_pipelines
    WHERE schedule_id = ? AND stage = 'upload'
    LIMIT 1
  `).get(schedule.id) as any;
  dbUpload.close();

  const uploadPipelineId = uploadPipeline?.id || (schedule.id + '_upload');
  console.log(`[Scheduler] Using upload pipeline ID: ${uploadPipelineId}`);

  addPipelineLog(uploadPipelineId, 'info', `Starting YouTube upload for video: ${videoResult.videoId}`);
  addTitleLog(schedule.title_id, 'info', `ğŸ“¤ YouTube ì—…ë¡œë“œ ì¤‘...`);
  updatePipelineStatus(uploadPipelineId, 'running');

  const uploadResult = await uploadToYouTube(videoResult.videoId, schedule, uploadPipelineId, maxRetry);

  if (!uploadResult.success) {
    throw new Error(`YouTube upload failed: ${uploadResult.error}`);
  }

  updatePipelineStatus(uploadPipelineId, 'completed');

  // video_schedules í…Œì´ë¸”ì— youtube_url ì €ì¥
  const db = new Database(dbPath);
  db.prepare(`
    UPDATE video_schedules
    SET youtube_url = ?, updated_at = CURRENT_TIMESTAMP
    WHERE id = ?
  `).run(uploadResult.videoUrl, schedule.id);
  db.close();

  addPipelineLog(uploadPipelineId, 'info', `YouTube upload successful: ${uploadResult.videoUrl}`);
  addTitleLog(schedule.title_id, 'info', `âœ… YouTube ì—…ë¡œë“œ ì™„ë£Œ: ${uploadResult.videoUrl}`);

  // Publish ë‹¨ê³„ - ê¸°ì¡´ pipeline ì°¾ê¸°
  const dbPublish = new Database(dbPath);
  const publishPipeline = dbPublish.prepare(`
    SELECT id FROM automation_pipelines
    WHERE schedule_id = ? AND stage = 'publish'
    LIMIT 1
  `).get(schedule.id) as any;
  dbPublish.close();

  const publishPipelineId = publishPipeline?.id || (schedule.id + '_publish');
  console.log(`[Scheduler] Using publish pipeline ID: ${publishPipelineId}`);

  addPipelineLog(publishPipelineId, 'info', `Scheduling YouTube publish`);
  addTitleLog(schedule.title_id, 'info', `ğŸ“… í¼ë¸”ë¦¬ì‹œ ì˜ˆì•½ ì¤‘...`);
  updatePipelineStatus(publishPipelineId, 'running');

  const publishResult = await scheduleYouTubePublish(uploadResult.uploadId || '', schedule, publishPipelineId);

  if (!publishResult.success) {
    throw new Error(`YouTube publish scheduling failed: ${publishResult.error}`);
  }

  updatePipelineStatus(publishPipelineId, 'completed');
  updateScheduleStatus(schedule.id, 'completed');
  updateTitleStatus(schedule.title_id, 'completed');

  addPipelineLog(publishPipelineId, 'info', `Pipeline completed successfully`);
  addTitleLog(schedule.title_id, 'info', `ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!`);

  console.log(`[Scheduler] Pipeline completed for schedule ${schedule.id}`);
}

// ========== ì™„ì „ ìë™í™”: ì±„ë„ ì£¼ê¸° ì²´í¬ ë° ìë™ ìŠ¤ì¼€ì¤„ ìƒì„± ==========

/**
 * ì±„ë„ë³„ ì£¼ê¸°ë¥¼ í™•ì¸í•˜ê³ , ì£¼ê¸°ê°€ ë„ë˜í–ˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì œëª© ìƒì„± â†’ ìŠ¤ì¼€ì¤„ ì¶”ê°€
 * 1. ëª¨ë“  í™œì„±í™”ëœ ì±„ë„ ì„¤ì • ì¡°íšŒ
 * 2. ê° ì±„ë„ì˜ ë‹¤ìŒ ìŠ¤ì¼€ì¤„ ì‹œê°„ ê³„ì‚°
 * 3. ë‹¤ìŒ ìŠ¤ì¼€ì¤„ì´ ì—†ìœ¼ë©´ (ë˜ëŠ” ì£¼ê¸°ê°€ ë„ë˜í–ˆìœ¼ë©´):
 *    - ì¹´í…Œê³ ë¦¬ì—ì„œ ëœë¤í•˜ê²Œ ì„ íƒ
 *    - AIë¡œ ì œëª© ìƒì„±
 *    - ì œëª© DBì— ì¶”ê°€
 *    - ìŠ¤ì¼€ì¤„ ìë™ ì¶”ê°€
 */
async function checkAndCreateAutoSchedules() {
  try {
    const db = new Database(dbPath);

    // 1. ëª¨ë“  í™œì„±í™”ëœ ì±„ë„ ì„¤ì • ì¡°íšŒ
    const channelSettings = db.prepare(`
      SELECT * FROM youtube_channel_settings
      WHERE is_active = 1
    `).all() as any[];

    db.close();

    if (channelSettings.length === 0) {
      console.log('[AutoScheduler] No active channel settings found');
      return;
    }

    console.log(`[AutoScheduler] Checking ${channelSettings.length} active channels for auto-scheduling`);

    for (const setting of channelSettings) {
      try {
        // categoriesê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„± ë¶ˆê°€
        if (!setting.categories) {
          console.log(`[AutoScheduler] Channel ${setting.channel_name}: No categories configured, skipping auto-generation`);
          continue;
        }

        const categories = JSON.parse(setting.categories);
        if (!categories || categories.length === 0) {
          console.log(`[AutoScheduler] Channel ${setting.channel_name}: Empty categories, skipping auto-generation`);
          continue;
        }

        // 2. ì´ ì±„ë„ì˜ ìµœê·¼ ìŠ¤ì¼€ì¤„ í™•ì¸
        const db2 = new Database(dbPath);
        const lastSchedule = db2.prepare(`
          SELECT s.*, t.channel
          FROM video_schedules s
          JOIN video_titles t ON s.title_id = t.id
          WHERE t.channel = ? AND t.user_id = ?
          ORDER BY s.scheduled_time DESC
          LIMIT 1
        `).get(setting.channel_id, setting.user_id) as any;
        db2.close();

        // 3. ë‹¤ìŒ ìŠ¤ì¼€ì¤„ ì‹œê°„ ê³„ì‚°
        const { calculateNextScheduleTime } = await import('./automation');
        const nextScheduleTime = calculateNextScheduleTime(
          setting.user_id,
          setting.channel_id,
          lastSchedule ? new Date(lastSchedule.scheduled_time) : undefined
        );

        if (!nextScheduleTime) {
          console.log(`[AutoScheduler] Channel ${setting.channel_name}: Could not calculate next schedule time`);
          continue;
        }

        // 4. ë‹¤ìŒ ìŠ¤ì¼€ì¤„ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        const db3 = new Database(dbPath);
        const existingSchedule = db3.prepare(`
          SELECT s.id
          FROM video_schedules s
          JOIN video_titles t ON s.title_id = t.id
          WHERE t.channel = ? AND t.user_id = ?
            AND s.scheduled_time >= ?
            AND s.status IN ('pending', 'processing')
          LIMIT 1
        `).get(
          setting.channel_id,
          setting.user_id,
          nextScheduleTime.toISOString()
        ) as any;
        db3.close();

        if (existingSchedule) {
          console.log(`[AutoScheduler] Channel ${setting.channel_name}: Schedule already exists for next time, skipping`);
          continue;
        }

        // 5. ì¹´í…Œê³ ë¦¬ì—ì„œ ëœë¤ ì„ íƒ
        const randomCategory = categories[Math.floor(Math.random() * categories.length)];

        console.log(`[AutoScheduler] Channel ${setting.channel_name}: Generating title for category "${randomCategory}"`);

        // 6. AIë¡œ ì œëª© ìƒì„± (generate-title-suggestions API í˜¸ì¶œ)
        const titleResponse = await fetch(`http://localhost:${process.env.PORT || 3000}/api/generate-title-suggestions`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            categories: [randomCategory],
            count: 1,
            youtubeTitles: [] // ê¸°ì¡´ ì œëª© ì—†ì´ ìƒˆë¡œ ìƒì„±
          })
        });

        if (!titleResponse.ok) {
          throw new Error(`Title generation failed: ${titleResponse.statusText}`);
        }

        const titleData = await titleResponse.json();
        const generatedTitle = titleData.titles?.[0];

        if (!generatedTitle) {
          throw new Error('No title generated');
        }

        console.log(`[AutoScheduler] Channel ${setting.channel_name}: Generated title "${generatedTitle}"`);

        // 7. ì œëª© DBì— ì¶”ê°€
        const { addVideoTitle } = await import('./automation');
        const titleId = addVideoTitle({
          title: generatedTitle,
          type: 'longform', // ê¸°ë³¸ê°’, í•„ìš” ì‹œ ì±„ë„ ì„¤ì •ì— ì¶”ê°€ ê°€ëŠ¥
          category: randomCategory,
          channel: setting.channel_id,
          scriptMode: 'chrome',
          mediaMode: 'dalle3',
          model: 'claude',
          userId: setting.user_id
        });

        console.log(`[AutoScheduler] Channel ${setting.channel_name}: Created title ${titleId}`);

        // 8. ìŠ¤ì¼€ì¤„ ìë™ ì¶”ê°€
        const { addSchedule } = await import('./automation');
        const scheduleId = addSchedule({
          titleId,
          scheduledTime: nextScheduleTime.toISOString(),
          youtubePrivacy: 'public' // ê¸°ë³¸ê°’, í•„ìš” ì‹œ ì±„ë„ ì„¤ì •ì— ì¶”ê°€ ê°€ëŠ¥
        });

        console.log(`[AutoScheduler] âœ… Channel ${setting.channel_name}: Auto-scheduled "${generatedTitle}" for ${nextScheduleTime.toISOString()}`);

        // 9. ë¡œê·¸ ì¶”ê°€
        const { addTitleLog } = await import('./automation');
        addTitleLog(titleId, 'info', `ğŸ¤– ì™„ì „ ìë™í™”: ì£¼ê¸° ë„ë˜ë¡œ ì œëª© ìë™ ìƒì„± ë° ìŠ¤ì¼€ì¤„ ì¶”ê°€ (ì±„ë„: ${setting.channel_name}, ì¹´í…Œê³ ë¦¬: ${randomCategory})`);

      } catch (channelError: any) {
        console.error(`[AutoScheduler] Error processing channel ${setting.channel_name}:`, channelError);
        // ê°œë³„ ì±„ë„ ì‹¤íŒ¨ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ
      }
    }

  } catch (error: any) {
    console.error('[AutoScheduler] Error in checkAndCreateAutoSchedules:', error);
  }
}
